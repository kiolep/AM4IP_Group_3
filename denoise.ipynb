{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "from PIL import Image\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/net/ens/am4ip/datasets/project-dataset\"\n",
    "rainyImagesPath = path + '/rainy_images'\n",
    "rainySsegPath = path + '/rainy_sseg'\n",
    "sunnyImagesPath = path + '/sunny_images'\n",
    "sunnySsegPath = path + '/sunny_sseg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 10\n",
    "\n",
    "# Initialize a list to store the images\n",
    "images_list = []\n",
    "\n",
    "# Iterate over the first `num_images` files in the folder\n",
    "for i, filename in enumerate(sorted(os.listdir(sunnyImagesPath))):\n",
    "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):  # Add other extensions if necessary\n",
    "        # Load the image\n",
    "        img_path = os.path.join(sunnyImagesPath, filename)\n",
    "        image = Image.open(img_path)\n",
    "        resized_image = image.resize((320, 480))\n",
    "        grayscale_image = resized_image.convert(\"L\")\n",
    "        img = np.array(grayscale_image)\n",
    "\n",
    "        images_list.append(np.array(img))  # Convert to numpy array and append to list\n",
    "        if len(images_list) >= num_images:  # Stop after reading `num_images`\n",
    "            break\n",
    "\n",
    "# Stack the images to create a 3D numpy array\n",
    "images_array = np.stack(images_list, axis=0)  # Shape: (10, n, n)\n",
    "\n",
    "print(f\"Images array shape: {images_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchig(data, patchsize=[64, 64], step=[16, 16]):\n",
    "    # find starting indices\n",
    "    x = np.arange(0, data.shape[0] - patchsize[0], step=step[0])\n",
    "    y = np.arange(0, data.shape[1] - patchsize[1], step=step[1])\n",
    "    TopLefts = list(itertools.product(x, y))\n",
    "\n",
    "    print('Extracting %i patches' % len(TopLefts))\n",
    "\n",
    "    patches = np.zeros([len(TopLefts), patchsize[0], patchsize[1]])\n",
    "\n",
    "    for i, pi in enumerate(TopLefts):\n",
    "        patches[i] = data[pi[0]:pi[0]+patchsize[0], pi[1]:pi[1]+patchsize[1]]\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisydata = images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "for noisy in noisydata:\n",
    "    noisyPatches = patchig(noisy,  patchsize=[32, 32], step=[20,20])\n",
    "    temp.append(noisyPatches)\n",
    "\n",
    "noisyPatches = np.concatenate(temp, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,6,figsize=[15,7])\n",
    "for i in range(6*3):\n",
    "    axs.ravel()[i].imshow(noisyPatches[i])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisyPatches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifyActivePixels(patch, numActivePixels, neighbourhoodRadius=5):\n",
    "    radius = neighbourhoodRadius\n",
    "\n",
    "    # Select active pixel locations\n",
    "    activeXCoords = np.random.randint(0, patch.shape[0], numActivePixels)\n",
    "    activeYCoords = np.random.randint(0, patch.shape[1], numActivePixels)\n",
    "    activePixelIndices = (activeXCoords, activeYCoords)\n",
    "    \n",
    "    # Select neighbouring pixel locations\n",
    "    # Compute shift for neighbouring pixels\n",
    "    xShift = np.random.randint(-radius // 2 + radius % 2, radius // 2 + radius % 2, numActivePixels)\n",
    "    yShift = np.random.randint(-radius // 2 + radius % 2, radius // 2 + radius % 2, numActivePixels)\n",
    "    \n",
    "    # Ensure no replacement with itself\n",
    "    for i in range(len(xShift)):\n",
    "        if xShift[i] == 0 and yShift[i] == 0:\n",
    "            shiftOptions = np.trim_zeros(np.arange(-radius // 2 + 1, radius // 2 + 1))\n",
    "            xShift[i] = np.random.choice(shiftOptions[shiftOptions != 0], 1)\n",
    "\n",
    "    # Find coordinates of neighbouring pixels\n",
    "    neighbourXCoords = activeXCoords + xShift\n",
    "    neighbourYCoords = activeYCoords + yShift\n",
    "    # Wrap indices within patch bounds\n",
    "    neighbourXCoords = neighbourXCoords + (neighbourXCoords < 0) * patch.shape[0] - (neighbourXCoords >= patch.shape[0]) * patch.shape[0]\n",
    "    neighbourYCoords = neighbourYCoords + (neighbourYCoords < 0) * patch.shape[1] - (neighbourYCoords >= patch.shape[1]) * patch.shape[1]\n",
    "    neighbourPixelIndices = (neighbourXCoords, neighbourYCoords)\n",
    "    \n",
    "    # Replace active pixel values with neighbours\n",
    "    modifiedPatch = patch.copy()\n",
    "    modifiedPatch[activePixelIndices] = patch[neighbourPixelIndices]\n",
    "    \n",
    "    # Create active pixel mask\n",
    "    activePixelMask = np.ones_like(patch)\n",
    "    activePixelMask[activePixelIndices] = 0.\n",
    "\n",
    "    return modifiedPatch, activePixelMask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crpt_patch, mask = modifyActivePixels(noisyPatches[6], numActivePixels=10, neighbourhoodRadius=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corruption(noisy,crpt,mask,seismic_cmap='RdBu',vmin=-0.25,vmax=0.25):\n",
    "    fig,axs = plt.subplots(1,3,figsize=[15,5])\n",
    "    axs[0].imshow(noisy)\n",
    "    axs[1].imshow(crpt)\n",
    "    axs[2].imshow(mask)\n",
    "\n",
    "    axs[0].set_title('Original')\n",
    "    axs[1].set_title('Corrupted')\n",
    "    axs[2].set_title('Corruption Mask')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig,axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plot_corruption(noisyPatches[6], crpt_patch, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the percentage of active pixels per patch\n",
    "percentActive = 2\n",
    "\n",
    "# Calculate the total number of pixels in a patch\n",
    "totalPixels = noisyPatches[0].shape[0] * noisyPatches[0].shape[1]\n",
    "\n",
    "# Determine the number of active pixels based on the chosen percentage\n",
    "numActivePixels = int(np.floor((totalPixels / 100) * percentActive))\n",
    "\n",
    "# Apply the pre-processing function with the selected values\n",
    "corruptedPatch, mask = modifyActivePixels(noisyPatches[6], numActivePixels=numActivePixels, neighbourhoodRadius=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myUnet import UNet\n",
    "\n",
    "model = UNet(input_channels=1, output_channels=1, hidden_channels=32, depth=2).to(device)   # grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001  # Learning rate\n",
    "criterion = nn.MSELoss()  # Loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 100  # most recommend 150-200 for random noise suppression \n",
    "\n",
    "# Choose number of training and validation samples\n",
    "numTrainingSamples = 2048\n",
    "numTestSamples = 512\n",
    "\n",
    "# Choose the batch size for the models training\n",
    "batchSize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise arrays to keep track of train and validation metrics\n",
    "trainLossHistory = np.zeros(numEpochs)\n",
    "trainAccuracyHistory = np.zeros(numEpochs)\n",
    "testLossHistory = np.zeros(numEpochs)\n",
    "testAccuracyHistory = np.zeros(numEpochs)\n",
    "\n",
    "# For reproducibility\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, lossFunction, optim, dataLoader, device):\n",
    "    model.train()\n",
    "    avgAccuracy = 0\n",
    "    avgLoss = 0\n",
    "\n",
    "    for batch in tqdm(dataLoader):\n",
    "        features, labels, exclusionMask = (\n",
    "            batch[0].to(device),\n",
    "            batch[1].to(device),\n",
    "            batch[2].to(device)\n",
    "        )\n",
    "        optim.zero_grad()\n",
    "        predictedProbs = model(features)\n",
    "        batchLoss = lossFunction(predictedProbs * (1 - exclusionMask), labels * (1 - exclusionMask))\n",
    "        batchLoss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        with torch.no_grad():\n",
    "            detachedPredictions = predictedProbs.detach().cpu().numpy().astype(float)\n",
    "\n",
    "        avgLoss += batchLoss.item()\n",
    "        avgAccuracy += np.sqrt(np.mean((labels.cpu().numpy().ravel() - detachedPredictions.ravel())**2))\n",
    "        \n",
    "    avgLoss /= len(dataLoader)\n",
    "    avgAccuracy /= len(dataLoader)\n",
    "\n",
    "    return avgLoss, avgAccuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, lossFunction, optim, dataLoader, device):\n",
    "    model.eval()\n",
    "    avgAccuracy = 0\n",
    "    avgLoss = 0\n",
    "\n",
    "    for batchData in tqdm(dataLoader):\n",
    "        inputFeatures, targetLabels, maskMatrix = (\n",
    "            batchData[0].to(device),\n",
    "            batchData[1].to(device),\n",
    "            batchData[2].to(device)\n",
    "        )\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        predictedOutput = model(inputFeatures)\n",
    "\n",
    "        with torch.no_grad():            \n",
    "            batchLoss = lossFunction(predictedOutput * (1 - maskMatrix), targetLabels * (1 - maskMatrix))\n",
    "            predictedValues = (predictedOutput.detach().cpu().numpy()).astype(float)\n",
    "        \n",
    "        avgLoss += batchLoss.item()  \n",
    "        avgAccuracy += np.sqrt(np.mean((targetLabels.cpu().numpy().ravel() - predictedValues.ravel())**2))  \n",
    "        \n",
    "    avgLoss /= len(dataLoader)  \n",
    "    avgAccuracy /= len(dataLoader)  \n",
    "\n",
    "    return avgLoss, avgAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataLoaders(noisyPatches, corruptedPatches, maskArray, numTrain, numTest, batchSize, torchGen):\n",
    "    trainInputs = np.expand_dims(corruptedPatches[:numTrain], axis=1)\n",
    "    trainTargets = np.expand_dims(noisyPatches[:numTrain], axis=1)\n",
    "    trainMasks = np.expand_dims(maskArray[:numTrain], axis=1)\n",
    "    trainingDataset = TensorDataset(\n",
    "        torch.from_numpy(trainInputs).float(),\n",
    "        torch.from_numpy(trainTargets).float(),\n",
    "        torch.from_numpy(trainMasks).float()\n",
    "    )\n",
    "\n",
    "    testInputs = np.expand_dims(corruptedPatches[numTrain:numTrain + numTest], axis=1)\n",
    "    testTargets = np.expand_dims(noisyPatches[numTrain:numTrain + numTest], axis=1)\n",
    "    testMasks = np.expand_dims(maskArray[numTrain:numTrain + numTest], axis=1)\n",
    "    testDataset = TensorDataset(\n",
    "        torch.from_numpy(testInputs).float(),\n",
    "        torch.from_numpy(testTargets).float(),\n",
    "        torch.from_numpy(testMasks).float()\n",
    "    )\n",
    "\n",
    "    # Create DataLoader\n",
    "    trainingLoader = DataLoader(trainingDataset, batch_size=batchSize, shuffle=True, generator=torchGen)\n",
    "    testingLoader = DataLoader(testDataset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "    return trainingLoader, testingLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(numEpochs):\n",
    "    # Randomly corrupt the noisy patches\n",
    "    corruptedPatches = np.zeros_like(noisyPatches)\n",
    "    patchMasks = np.zeros_like(corruptedPatches)\n",
    "    for patchIndex in range(len(noisyPatches)):\n",
    "        corruptedPatches[patchIndex], patchMasks[patchIndex] = modifyActivePixels(noisyPatches[patchIndex], numActivePixels=int(numActivePixels), neighbourhoodRadius=5)\n",
    "\n",
    "    # Create data loaders using the predefined function\n",
    "    trainLoader, testLoader = createDataLoaders(noisyPatches, corruptedPatches, patchMasks, numTrainingSamples, numTestSamples, batchSize=batchSize, torchGen=g)\n",
    "\n",
    "    # Train the model\n",
    "    trainLoss, trainAccuracy = trainModel(model=model, lossFunction=criterion, optim=optimizer, dataLoader=trainLoader, device=device)\n",
    "    trainLossHistory[epoch], trainAccuracyHistory[epoch] = trainLoss, trainAccuracy\n",
    "\n",
    "    # Evaluate the model (validation)\n",
    "    testLoss, testAccuracy = evaluateModel( model=model, lossFunction=criterion, optim=optimizer, dataLoader=testLoader, device=device)\n",
    "    testLossHistory[epoch], testAccuracyHistory[epoch] = testLoss, testAccuracy\n",
    "\n",
    "    # Print training progress\n",
    "    print(f\"\"\"Epoch {epoch}, Training Loss: {trainLoss:.4f}, Training Accuracy: {trainAccuracy:.4f},  Test Loss: {testLoss:.4f}, Test Accuracy: {testAccuracy:.4f}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics(trainAccuracyHistory, testAccuracyHistory, trainLossHistory, testLossHistory):\n",
    "    fig,axs = plt.subplots(1,2,figsize=(15,4))\n",
    "    \n",
    "    axs[0].plot(trainAccuracyHistory, 'r', lw=2, label='train')\n",
    "    axs[0].plot(testAccuracyHistory, 'k', lw=2, label='validation')\n",
    "    axs[0].set_title('RMSE', size=16)\n",
    "    axs[0].set_ylabel('RMSE', size=12)\n",
    "\n",
    "    axs[1].plot(trainLossHistory, 'r', lw=2, label='train')\n",
    "    axs[1].plot(testLossHistory, 'k', lw=2, label='validation')\n",
    "    axs[1].set_title('Loss', size=16)\n",
    "    axs[1].set_ylabel('Loss', size=12)\n",
    "    \n",
    "    for ax in axs:\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('# Epochs', size=12)\n",
    "    fig.tight_layout()\n",
    "    return fig,axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plot_training_metrics(trainAccuracyHistory, testAccuracyHistory, trainLossHistory, testLossHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = noisydata[5]\n",
    "print(testdata.shape)\n",
    "# Convert dataset in tensor for prediction purposes\n",
    "torch_testdata = torch.from_numpy(np.expand_dims(np.expand_dims(testdata,axis=0),axis=0)).float()\n",
    "print(torch_testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_prediction = model(torch_testdata.to(device))\n",
    "\n",
    "# Return to numpy for plotting purposes\n",
    "test_pred = test_prediction.detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(test_pred, cmap='gray')\n",
    "plt.title('Test Prediction')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'denoisingModel.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
